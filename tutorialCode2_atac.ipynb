{
 "cells": [
  {
   "cell_type": "raw",
   "id": "307a903e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"ATAC-seq Tutorial\"\n",
    "output: \n",
    "  html_document:\n",
    "    toc: true \n",
    "    number_sections: true\n",
    "    toc_depth: 3\n",
    "    toc_float: true \n",
    "    css: scripts/custom.css\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131e0ab",
   "metadata": {},
   "source": [
    "# loading packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c4136-6cc2-487c-bd27-722b656ef68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#bioconductor\n",
    "library(\"GenomicRanges\")\n",
    "library(\"DESeq2\")\n",
    "library(\"ACME\")\n",
    "library(\"GEOquery\")\n",
    "library(\"EnhancedVolcano\")\n",
    "\n",
    "#R \n",
    "library(\"stringr\")\n",
    "library(\"dplyr\")\n",
    "library(\"parallel\")\n",
    "library(\"rmarkdown\")\n",
    "library(\"knitr\")\n",
    "library(\"ggfortify\")\n",
    "library(\"data.table\")\n",
    "library(\"ggrepel\")\n",
    "\n",
    "#define the input path\n",
    "filepath <- c(\"/public/codelab/omics-workshop/OmicsWorkshopVignettes/03_BulkRNAATAC_KithXiang/data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04664798-7d2a-4746-84d9-d29a99444bd1",
   "metadata": {},
   "source": [
    "# ATAC-seq\n",
    "\n",
    "An ATAC-seq analysis is very similar to RNA-seq.  Once we have the count matrix, almost\n",
    "all the steps are the same.  \n",
    "\n",
    "# Processesing from scratch\n",
    "\n",
    "The preparation of the count matrix from the fastq files is what takes the most\n",
    "time and effort and though it's possible to do this all on a laptop, \n",
    "it's usually better to do the computationally heavy parts on the HPC.\n",
    "\n",
    "A typical ATAC-seq pipeline involves the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a36cb7",
   "metadata": {},
   "source": [
    "## Quality control & adapter trimming\n",
    "\n",
    "Just like RNA-seq, we should run QC on the reads and trim adapters before going further with the processing.\n",
    "\n",
    "[*fastqc*](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/), \n",
    "[*trim_galore*](https://github.com/FelixKrueger/TrimGalore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488dfc4",
   "metadata": {},
   "source": [
    "## Alignment\n",
    "\n",
    "Alignment of ATACseq data is in a sense easier than RNAseq, because we don't have to\n",
    "consider the splicing of reads over exons.\n",
    "\n",
    "[*bowtie2*](https://bowtie-bio.sourceforge.net/bowtie2/manual.shtml) is a popular option for this step\n",
    "and can be run on the HPC or even a laptop.\n",
    "\n",
    "Its main input parameters are the location of the indexed reference genome and the fastq files, and\n",
    "the default options work well for ATACseq data.  \n",
    "\n",
    "A quirk of this program is that it has trouble reading zipped files, so you either have to unzip\n",
    "your compressed fastq files beforehand, or better yet, use \n",
    "[process substitution](https://en.wikipedia.org/wiki/Process_substitution)\n",
    "at the command line to avoid\n",
    "temp files.  The alignments come out in SAM format, and if you want binary output, \n",
    "you can pipe it to [*samtools*](http://www.htslib.org/doc/samtools.html) to save\n",
    "as a BAM. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "610b38ed",
   "metadata": {
    "eval": false,
    "lines_to_next_cell": 0
   },
   "source": [
    "%%bash\n",
    "REF=~/projects/GRCh38_no_alt_analysis/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index\n",
    "\n",
    "bowtie2 -t -p 8 -q --local -x $REF -1 <(zcat $FQ1) -2 <(zcat $FQ2) 2>| \\\n",
    "    summary_${SNAME}.txt | samtools view -bS - >| ${SNAME}.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0350c5",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36308a4",
   "metadata": {},
   "source": [
    "## Marking PCR duplicates\n",
    "\n",
    "Steps should be taken to ensure that we'll be using one single read per physical fragment of our ATACseq library.\n",
    "Multiple copies of reads can come from PCR or optical duplication and we need a way to mark them, \n",
    "and to make sure we're using the one with the best quality.\n",
    "\n",
    "The [*MarkDuplicates*](https://gatk.broadinstitute.org/hc/en-us/articles/360037052812-MarkDuplicates-Picard-) \n",
    "feature of the [*picard-tools*](https://broadinstitute.github.io/picard/) software suite does this nicely, \n",
    "adding a flag to each read of the bam telling if it should be used or not.  As this is such \n",
    "a common step, most downstream programs take this\n",
    "BAM [*flag*](http://broadinstitute.github.io/picard/explain-flags.html) \n",
    "into consideration, so manually removing the the duplicates usually isn't required.\n",
    "\n",
    "Before running `MarkDuplicates`, you'll need to sort your bam file.\n",
    "After running `MarkDuplicates`, it's a good idea to index your bam.  This speeds up\n",
    "query operations and lets downstream programs jump to locations without having to read in\n",
    "the entire file."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd0721dc",
   "metadata": {
    "eval": false
   },
   "source": [
    "%%bash\n",
    "picard SortSam INPUT=${SNAME}.bam OUTPUT=${SNAME}_sorted.bam SO=coordinate \\\n",
    "    CREATE_INDEX=true MAX_RECORDS_IN_RAM=1000000 TMP_DIR=tmp\n",
    "\n",
    "picard MarkDuplicates INPUT=${SNAME}_sorted.bam OUTPUT=${SNAME}_sorted_mdup.bam \\\n",
    "    METRICS_FILE=${SNAME}_mdMetric.txt \n",
    "\n",
    "picard BuildBamIndex INPUT=${SNAME}_sorted_mdup.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b9da98",
   "metadata": {},
   "source": [
    "## Peak detection\n",
    "\n",
    "Once the reads have been mapped into a sorted BAM file, figuring out where the reads fall into peaks can be done \n",
    "with a program called [*Model-based Analysis of ChIP-seq (MACS)*](https://hbctraining.github.io/Intro-to-ChIPseq/lessons/05_peak_calling_macs.html).\n",
    "\n",
    "It was originally designed for finding trascription binding sites in ChIP-seq experiments, but there\n",
    "are options that allow it to be run without having an input control sample.  It uses a\n",
    "technique called *lamda shifting* to estimate background signal in the local region around a potential peak,\n",
    "and a Poisson model is used to determine its significance. \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58f0e8ce",
   "metadata": {
    "eval": false
   },
   "source": [
    "%%bash\n",
    "macs2 callpeak -f BAMPE -t $BAM -n $SNAME --outdir $FOL --verbose 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002329b1",
   "metadata": {},
   "source": [
    "The main output from the program are the locations of the peaks that were detected in various\n",
    "formats(bed,xls)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177a2ca",
   "metadata": {},
   "source": [
    "## Running the pipeline\n",
    "\n",
    "The steps described above are the most computationally intensive, so running them \n",
    "on the HPC is recommended.  The script below shows an example of how to process a set of trimmed\n",
    "fastq files with the programs available on the cluster using the \n",
    "`sbatch` command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74ff1c8a",
   "metadata": {
    "eval": false
   },
   "source": [
    "%%bash\n",
    "#trim the adapters\n",
    "cd fq\n",
    "trim_galore --paired *.fastq.gz\n",
    "\n",
    "\n",
    "for fq1 in trimmed/*1_val_1*\n",
    "do\n",
    "    echo $fq1\n",
    "    fq2=`echo $fq1 | sed 's/R1_001_val_1/R2_001_val_2/'`\n",
    "    echo $fq2\n",
    "    nam=`echo $fq1 | sed 's/\\..*//' | sed 's/trimmed\\\\///'`\n",
    "    echo $nam\n",
    "    sbatch slurm_peakPipeline.sh $nam $fq1 $fq2\n",
    "done \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6567a",
   "metadata": {},
   "source": [
    "### slurm_peakPipeline.sh"
   ]
  },
  {
   "cell_type": "raw",
   "id": "326cdf60",
   "metadata": {
    "eval": false,
    "file": "scripts/slurm_peakPipeline.sh",
    "lines_to_next_cell": 2
   },
   "source": [
    "%%sh\n",
    "#SBATCH --partition normal\n",
    "#SBATCH --job-name=peakPipeline\n",
    "#SBATCH --output=peakPipeline_%j\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH -n 1\n",
    "#SBATCH --ntasks-per-node=10\n",
    "#SBATCH --time=48:0:0\n",
    "\n",
    "#maybe run ~/.bashrc?\n",
    "\n",
    "source ~/.bashrc\n",
    "\n",
    "conda activate bio-python2\n",
    "\n",
    "PATH=$PATH:/gs/gsfs0/hpc01/rhel8/apps/conda3/envs/biobase/bin/\n",
    "\n",
    "REF=~/projects/GRCh38_no_alt_analysis/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index\n",
    "\n",
    "SNAME=$1\n",
    "FQ1=$2\n",
    "FQ2=$3\n",
    "\n",
    "\n",
    "bowtie2 -t -p 8 -q --local -x $REF -1 <(zcat $FQ1) -2 <(zcat $FQ2) 2>| \\\n",
    "    summary_${SNAME}.txt | samtools view -bS - >| ${SNAME}.bam\n",
    "\n",
    "picard SortSam INPUT=${SNAME}.bam OUTPUT=${SNAME}_sorted.bam SO=coordinate \\\n",
    "    CREATE_INDEX=true MAX_RECORDS_IN_RAM=1000000 TMP_DIR=tmp\n",
    "\n",
    "picard MarkDuplicates INPUT=${SNAME}_sorted.bam OUTPUT=${SNAME}_sorted_mdup.bam \\\n",
    "    METRICS_FILE=${SNAME}_mdMetric.txt \n",
    "\n",
    "picard BuildBamIndex INPUT=${SNAME}_sorted_mdup.bam\n",
    "\n",
    "\n",
    "\n",
    "BAM=${SNAME}_sorted_mdup.bam\n",
    "FOL=macs_${SNAME}\n",
    "macs2 callpeak -f BAMPE -t $BAM -n $SNAME --outdir $FOL --verbose 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca63fd72",
   "metadata": {},
   "source": [
    "## Enumerating peaks\n",
    "\n",
    "Once we have the bam(aligned reads) and xls(detected peaks) files, we can\n",
    "count the number of reads falling in each peak region for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c469e1",
   "metadata": {},
   "source": [
    "### Merging peaks\n",
    "\n",
    "First we get a composite set of peaks merged from the ranges of all of our samples.\n",
    "Peak detection is run on all samples individually, then those results are merged\n",
    "together and collected into a single set that is the union of all the ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ab362",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#load in the peak files\n",
    "pfiles = list.files(path=paste0(filepath,\"/macsResults\"), recursive=T, pat=\"^.*xls$\", full=T)\n",
    "peaks = lapply(pfiles, read.table, header=T)\n",
    "\n",
    "#contruct genomic ranges of the peak summits +/- 200bp\n",
    "ranges = lapply(peaks, function(peak){\n",
    "\tGRanges(seqnames = peak[,1], \n",
    "        strand=rep(\"*\", nrow(peak)), \n",
    "            IRanges(start = peak[,2], end = peak[,3]))\n",
    "})\n",
    "peaks.reduced = reduce(do.call(c, ranges))\n",
    "\n",
    "#save genomic range as a bed file\n",
    "#https://www.biostars.org/p/89341/\n",
    "grange2bed <- function(gr, bfile=\"foo.bed\"){\n",
    "\n",
    "\tdf <- data.frame(seqnames=seqnames(gr),\n",
    "\t\tstarts=start(gr)-1,\n",
    "\t\tends=end(gr),\n",
    "\t\tnames=c(rep(\".\", length(gr))),\n",
    "\t\tscores=c(rep(\".\", length(gr))),\n",
    "\t\tstrands=strand(gr))\n",
    "\n",
    "\twrite.table(df, file=bfile, quote=F, sep=\"\\t\", row.names=F, col.names=F)\n",
    "}\n",
    "\n",
    "grange2bed(peaks.reduced, bfile=\"peaks_stat.bed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca5523",
   "metadata": {},
   "source": [
    "### Counting reads\n",
    "\n",
    "For every sample, we use these ranges to count the number of reads falling within the peaks.\n",
    "\n",
    "This can be done with a program called\n",
    "[*bedmap*](https://bedops.readthedocs.io/en/latest/content/reference/statistics/bedmap.html)\n",
    "from the [*BEDOPS*](https://bedops.readthedocs.io/en/latest/)\n",
    "toolkit.\n",
    "\n",
    "bedmap requires the input to be in .bed format, so in the script below the bam file is converted on the fly\n",
    "with process substitution and the output is saved in a txt file."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a47e9e64",
   "metadata": {
    "eval": false,
    "lines_to_next_cell": 0
   },
   "source": [
    "%%sh\n",
    "\n",
    "mkdir counts\n",
    "for bam in /home/kpradhan/mnt/hpc_home/projects/opeyemi/*atac*/*mdup.bam\n",
    "do\n",
    "    #echo $bam\n",
    "    nam=`echo $bam | sed 's$.*/$$' | sed 's/_.*//'`\n",
    "    #echo $nam\n",
    "    cnt=${nam}.counts\n",
    "    #echo $cnt\n",
    "    echo \"bedmap --echo --count --fraction-map .01 peaks_stat.bed <(bam2bed --sort-tmpdir=tmp < $bam) >| counts/$cnt\"\n",
    "done >| run1.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f24f7",
   "metadata": {},
   "source": [
    "This step can take a while so these precomputed count files have been included in\n",
    "the vingette's `data/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79feaef8",
   "metadata": {},
   "source": [
    "## Loading peaks into R\n",
    "The previous steps show us how to create count files for each sample showing the read coverages of every peak range.  \n",
    "They are simple .txt files and can be loaded into R very quickly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pfiles = list.files(path=paste0(filepath,\"/counts_atac\"), pat=\"*counts\", full=T)\n",
    "\n",
    "#load in 1 file to have a look at the format\n",
    "x = read.csv(pfiles[1], sep=\"\\t\", header=F)\n",
    "head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process all the count files\n",
    "pcounts = lapply(pfiles, function(file){\n",
    "    #print(file)\n",
    "\tx = read.csv(file, sep=\"\\t\", header=F)\n",
    "    #extract the number that appears after the *| in the 6th column of the input\n",
    "\thits = as.numeric(gsub(x[,6], pat=\"\\\\*\\\\|\", rep=\"\"))\n",
    "\ty = data.frame(chr=x[,1], start=x[,2], end=x[,3], counts=hits)\n",
    "\ty\n",
    "})\n",
    "#bind the counts together as columns in a matrix\n",
    "peakdata = do.call(cbind, lapply(pcounts, function(a){\n",
    "\ta$counts\n",
    "}))\n",
    "#give the columns better looking names. \n",
    "#grab the strings between the last \"/\" and \".counts\" \n",
    "colnames(peakdata) = gsub(pfiles, pat=\".*/(.*).counts\", rep=\"\\\\1\")\n",
    "\n",
    "\n",
    "#peak locations\n",
    "peaks = pcounts[[1]][,1:3]\n",
    "head(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb03f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a descriptive string ID for the peak \n",
    "peaknames = sapply(1:nrow(peaks), function(i){\n",
    "\tpaste0(peaks[i,1:3], collapse=\"_\")\n",
    "})\n",
    "rownames(peakdata) = peaknames\n",
    "cbind(head(rownames(peakdata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa2da8",
   "metadata": {
    "cache": true,
    "lines_to_next_cell": 0,
    "warning": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#get rid of NA counts\n",
    "ix2 = which(apply(peakdata, 1, function(a){\n",
    "    !any(is.na(a))\n",
    "}))\n",
    "peakdata=peakdata[ix2,]\n",
    "\n",
    "dim(peakdata)\n",
    "head(peakdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c60b43",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c2fb2",
   "metadata": {},
   "source": [
    "# Running Deseq\n",
    "From this point on, the files are processed and we're working with a count matrix that\n",
    " can be analyzed in the usual way.  The main difference is that the features are now peak id's\n",
    "instead of genes.  This doesn't change the way DESeq2 handles the data, but downstream analysis\n",
    "will need to be adjusted, usually by appending info of the nearest gene and filtering peaks \n",
    "too far away from points of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6765359",
   "metadata": {},
   "source": [
    "We already have our count matrix ready, now we need to create the phenotype data.frame.\n",
    "You might find it easier to prepare this in an excel spreadsheet first then load it into R.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "info <- colnames(peakdata)\n",
    "comp1 <- rep(NA, length(info))\n",
    "comp1[1:2] <- \"ctrl\"\n",
    "comp1[3:4] <- \"drug_treated\"\n",
    "coldata <- data.frame(info, comp1)\n",
    "\n",
    "#always make sanity checks with your own data\n",
    "#the row order of coldata needs to match the column order of peakdata\n",
    "all(coldata$info == colnames(peakdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c7c0c",
   "metadata": {
    "cache": true,
    "lines_to_next_cell": 2,
    "message": false
   },
   "outputs": [],
   "source": [
    "\n",
    "head(coldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the analysis\n",
    "dds <- DESeqDataSetFromMatrix(countData = peakdata,\n",
    "\t\t\t\t\t\t\t\t  colData = coldata,\n",
    "\t\t\t\t\t\t\t\t  design = ~ comp1)\n",
    "dds <- DESeq(dds)\n",
    "res <- results(dds)\n",
    "res <- as.data.frame(res)\n",
    "\n",
    "head(res, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a13f21",
   "metadata": {},
   "source": [
    "## A generalized function\n",
    "\n",
    "If you're going to be working on more than one set of samples, it makes\n",
    "sense to wrap up the DESEq2 analysis and any post processing routines\n",
    "into a function which can be applied to each comparison group.\n",
    "\n",
    "In the function below, we're calling DESeq2 as usual, then tacking on\n",
    "peak info and the raw & normalized peak counts to the resulting data.frame,\n",
    "then saving the output to a txt file.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe16252",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#run DESeq, add peak info, sort and write as a csv.\n",
    "#countdata: a matrix of integer counts, (nPeak x nSamples)\n",
    "#coldata: a data.frame with info on the samples (nSamples x nVariables)\n",
    "#ix: the indices of the samples you want to use in the analysis.\n",
    "#formula: shows which columns of coldata you want to use in the analysis\n",
    "#resFile: is where to save the result file\n",
    "runDE <- function(countdata, coldata, ix, formula = formula(\"~ ep300\"), resFile){\n",
    "\n",
    "\tdds = DESeqDataSetFromMatrix(countData = countdata[,ix],\n",
    "\t\t\t\t\t\t\t\t  colData = coldata[ix,],\n",
    "\t\t\t\t\t\t\t\t  design = formula)\n",
    "\tdds <- updateObject(dds)\n",
    "\tdds = DESeq(dds)\n",
    "\tres = results(dds)\n",
    "\ty = data.frame(res)\n",
    "\n",
    "    #break the peak identifier into parts\n",
    "    pos = data.frame(pid = rownames(y), str_split_fixed(rownames(y), \"_\", 3))\n",
    "    colnames(pos)[2:4] = c(\"chrom\", \"start\", \"stop\")\n",
    "    pos$start = as.numeric(pos$start)\n",
    "    pos$stop = as.numeric(pos$stop)\n",
    "    pos$mid = round((pos$stop+pos$start)/2)\n",
    "\ty = cbind(pos, y)\n",
    "\n",
    "    #add peak counts\n",
    "\tdiffexp = merge(y, countdata[,ix], by.x=1, by.y=0, all=T)\n",
    "\n",
    "\t#append the normalized counts to the matrix\n",
    "\tnorm.counts = counts(dds, normalized=T)\n",
    "\tcolnames(norm.counts) = paste0(\"norm_\",dds$info)\n",
    "\ty = merge(diffexp, norm.counts, by.x=1, by.y=0, all=T)\n",
    "\n",
    "    #sort results by fold change\n",
    "\ty = y[order(y[,\"log2FoldChange\"]),]\n",
    "\n",
    "    #add a chromosomal position to make IGV navigation easier\n",
    "    y$chrpos = paste0(y$chrom, \":\", y$start, \"-\", y$stop)\n",
    "\n",
    "\twrite.table(file=resFile, x=y, row.names=F, sep=\"\\t\")\n",
    "\n",
    "    #also return the results\n",
    "    y\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba86706",
   "metadata": {},
   "source": [
    "## Calling the function\n",
    "\n",
    "Once the function is written, it's much easier to run different comparison groups\n",
    "just by calling it with different parameters.  It's not too helpful in this example, but imagine\n",
    "you had a larger cohort of samples all treated with different drugs and experimental\n",
    "conditions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067f05b",
   "metadata": {
    "cache": true,
    "warning": false
   },
   "outputs": [],
   "source": [
    "#use the non-NA samples in comp1\n",
    "ix = which(!is.na(coldata$comp1))\n",
    "#or you can do it like\n",
    "#ix = 1:4\n",
    "\n",
    "#run the analysis\n",
    "res = runDE(peakdata, coldata, ix, formula(\"~ comp1\"), \"de_CtrlVsDrug.txt\")\n",
    "\n",
    "#view some of the results\n",
    "head(res, 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc6b3e",
   "metadata": {},
   "source": [
    "## Annotating peak locations\n",
    "\n",
    "You will most likely need to understand where the peaks are in relation to the genes of\n",
    "your reference genome.  The `ACME` bioconductor package has an easy to use function that\n",
    "can do this, which we can wrap in an `mclapply` call to run it in parallel over multiple cores.\n",
    "\n",
    "The function below tacks on information of the closest gene to each peak, \n",
    "and includes the distance to the transcription start site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc07191",
   "metadata": {},
   "source": [
    "For illustrative purposes and to make this run faster, \n",
    "we'll just work with the regions that have padj < 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "appendClosestGeneInfo <- function(x, chr=1, pos = 2, genome=\"hg19\", numCores = 1){\n",
    "\tres = mclapply(1:nrow(x), function(i){\n",
    "\t\tif (i %% 1000 == 0){\n",
    "\t\t\tprint(i)\n",
    "\t\t}\n",
    "\t\tgenes = findClosestGene(x[i,chr],x[i, pos],genome)\n",
    "\t\t#if there's more than one, just take the first\n",
    "\t\tdata.frame(genes[1,])\n",
    "\t}, mc.cores = numCores)\n",
    "\n",
    "\tx.res = bind_rows(res)\n",
    "\tcbind(x.res, x)\n",
    "}\n",
    "\n",
    "#how many peaks show significant DE?\n",
    "ix.sig = which(res$padj < 0.05)\n",
    "length(ix.sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049539f",
   "metadata": {
    "cache": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#show off the function using a small portion of the data\n",
    "res2 = appendClosestGeneInfo(x=res[ix.sig,], chr=2, pos=5, genome=\"hg38\") \n",
    "\n",
    "#if you get an error, try running on a single thread\n",
    "#res2 = appendClosestGeneInfo(x=res[ix.sig,], chr=2, pos=5, genome=\"hg38\", numCores=1) \n",
    "\n",
    "#if you still get an error, there may be issues with the web host(see below)\n",
    "\n",
    "head(res2, 50)\n",
    "write.csv(file=\"deAnno_padj0.05_CtrlVsDrug.txt\", x=res2, row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3351194-d196-468f-b1be-6248d48f6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#I've run into intermittent problems with the code above.\n",
    "#the original site that hosts the reference database occasionally goes offline\n",
    "#If you still want to use the code above, you can hack some of the functions inside\n",
    "#the ACME package to make it point to a different host\n",
    "\n",
    "\n",
    "# mygetRefflat <- function (genome = \"hg38\"){\n",
    "#     tmpfile <- tempfile()\n",
    "#     download.file(paste(\"http://hgdownload.soe.ucsc.edu/goldenPath/\", \n",
    "#         genome, \"/database/refFlat.txt.gz\", sep = \"\"), tmpfile, \n",
    "#         mode = \"wb\")\n",
    "#     rf <- read.delim(conn <- gzfile(tmpfile, open = \"rt\"), header = FALSE, \n",
    "#         sep = \"\\t\")\n",
    "#     close(conn)\n",
    "#     colnames(rf) <- c(\"geneName\", \"name\", \"chrom\", \"strand\", \n",
    "#         \"txStart\", \"txEnd\", \"cdsStart\", \"cdsEnd\", \"exonCount\", \n",
    "#         \"exonStarts\", \"exonEnds\")\n",
    "#     txEndNeg <- rf$txStart\n",
    "#     txStartNeg <- rf$txEnd\n",
    "#     cdsStartNeg <- rf$cdsEnd\n",
    "#     cdsEndNeg <- rf$cdsStart\n",
    "#     NegStrand <- rf$strand == \"-\"\n",
    "#     rf[NegStrand, \"cdsEnd\"] <- cdsEndNeg[NegStrand]\n",
    "#     rf[NegStrand, \"cdsStart\"] <- cdsStartNeg[NegStrand]\n",
    "#     rf[NegStrand, \"txEnd\"] <- txEndNeg[NegStrand]\n",
    "#     rf[NegStrand, \"txStart\"] <- txStartNeg[NegStrand]\n",
    "#     return(rf)\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c03a3-6b30-4a01-88aa-929fc86fd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myfindClosestGene <- function (chrom, pos, genome = \"hg38\", position = \"txStart\"){\n",
    "#     if (!exists(\"refflat\")) {\n",
    "#         reftmp <- list()\n",
    "#         reftmp[[genome]] <- mygetRefflat(genome)\n",
    "#         assign(\"refflat\", reftmp, .GlobalEnv)\n",
    "#     }\n",
    "#     else if (!(genome %in% names(refflat))) {\n",
    "#         refflat[[genome]] <<- mygetRefflat(genome)\n",
    "#     }\n",
    "#     rf <- refflat[[genome]]\n",
    "#     chromsub <- rf$chrom == chrom\n",
    "#     diffdist <- rf[chromsub, position] - pos\n",
    "#     sub <- which(abs(diffdist) == min(abs(diffdist)))\n",
    "#     rf <- rf[chromsub, 1:9][sub, ]\n",
    "#     return(data.frame(rf, Distance = diffdist[sub]))\n",
    "# }\n",
    "\n",
    "# #now you can try again\n",
    "# appendClosestGeneInfo2 <- function(x, chr=1, pos = 2, genome=\"hg38\", numCores = 4){\n",
    "# \tres = mclapply(1:nrow(x), function(i){\n",
    "# \t\tif (i %% 1000 == 0){\n",
    "# \t\t\tprint(i)\n",
    "# \t\t}\n",
    "# \t\tgenes = myfindClosestGene(x[i,chr],x[i, pos],genome)\n",
    "# \t\t#if there's more than one, just take the first\n",
    "# \t\tdata.frame(genes[1,])\n",
    "# \t}, mc.cores = numCores)\n",
    "\n",
    "# \tx.res = bind_rows(res)\n",
    "# \tcbind(x.res, x)\n",
    "# }\n",
    "\n",
    "\n",
    "# res2 = appendClosestGeneInfo2(x=res[ix.sig,], chr=2, pos=5, genome=\"hg38\") \n",
    "# head(res2, 50)\n",
    "# write.csv(file=\"deAnno_padj0.05_CtrlVsDrug.txt\", x=res2, row.names=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68afcc3b",
   "metadata": {},
   "source": [
    "## Visualizing peaks\n",
    "\n",
    "Once the interesting regions are found with DESeq2, [IGV](https://www.igv.org/) \n",
    "can be used to show off the differences visually.\n",
    "The aligned read files(.bam),can be loaded directly into IGV, or you can\n",
    "create coverage files(.tdf) with drag/drop tools from within IGV.\n",
    "The .tdfs are much smaller than .bams but only contain info on the read depths\n",
    "averaged over a sliding window and are normalized by library size.\n",
    "\n",
    "If you install IGV on your own computer, you can access its command line\n",
    "tools which allow you batch process multiple files at once."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3281c8c3",
   "metadata": {
    "eval": false
   },
   "source": [
    "%%bash\n",
    "#convert to bigwig and tdf\n",
    "for bam in *sorted_mdup.bam\n",
    "do\n",
    "    nam=`echo $bam | sed 's/.bam//'`\n",
    "    #echo \"echo $nam\"\n",
    "    #echo \"bamCoverage -b $bam -o ${nam}_normRpkm.bw --normalizeUsing RPKM\"\n",
    "    echo \"igvtools count -z 10 $bam $nam.tdf hg38\"\n",
    "done >| run2.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d303f5f",
   "metadata": {},
   "source": [
    "IGV comes preloaded with many different reference genomes, so make sure\n",
    "you select the same one that was used to do your own alignment or your plots\n",
    "won't make sense.\n",
    "\n",
    "If you're not well versed in R, you may feel more comfortable working through your\n",
    "DE results in excel, sorting by the adjusted p-value and filtering by logFC and/or distance\n",
    "to TSS.  If you're using the `runDE(...)` function defined above, the very last column of the result file \n",
    "will have the **chromosomal position** of the peak region in the form *chr:start-stop*.  This specific\n",
    "format is used in many downstream tools, including IGV, and can be copy/pasted into the location field to\n",
    "navigate to interesting regions quickly.\n",
    "\n",
    "![](data/igv_snapshot1.png)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "eval,tags,message,warning,language,file,cache,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R [conda env:spatial_singulomics]",
   "language": "R",
   "name": "conda-env-spatial_singulomics-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
