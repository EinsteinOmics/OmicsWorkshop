{
 "cells": [
  {
   "cell_type": "raw",
   "id": "732d0270",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"RNA-seq Tutorial\"\n",
    "output: \n",
    "  html_document:\n",
    "    toc: true \n",
    "    number_sections: true\n",
    "    toc_depth: 3\n",
    "    toc_float: true \n",
    "    css: scripts/custom.css\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ab9b1-c104-41ba-98ea-12660b5b2f49",
   "metadata": {},
   "source": [
    "# Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a81e8-d481-43c1-8514-c14e4c1ee25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#bioconductor\n",
    "library(\"GenomicRanges\")\n",
    "library(\"DESeq2\")\n",
    "library(\"ACME\")\n",
    "library(\"GEOquery\")\n",
    "library(\"EnhancedVolcano\")\n",
    "\n",
    "#R \n",
    "library(\"stringr\")\n",
    "library(\"dplyr\")\n",
    "library(\"parallel\")\n",
    "library(\"rmarkdown\")\n",
    "library(\"knitr\")\n",
    "library(\"ggfortify\")\n",
    "library(\"data.table\")\n",
    "library(\"ggrepel\")\n",
    "\n",
    "#define the input path\n",
    "filepath <- c(\"/public/codelab/omics-workshop/OmicsWorkshopVignettes/03_BulkRNAATAC_KithXiang/data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819825d-c83b-42b4-80fd-abd204ded8e9",
   "metadata": {},
   "source": [
    "# RNA-seq\n",
    "\n",
    "A typical analysis of RNAseq data involves mapping the reads to a reference genome and quantifying the expression\n",
    "of the genes in order to determine which have significant differential between experimental groups. \n",
    "\n",
    "Processing the raw data into a count matrix requires a number of steps, and though it's possible to do it all on a laptop,\n",
    "it's much preferred to use the HPC.  We're using R for most of the downstream analysis, but the preprocessing is\n",
    "usually done with other bioinformatics tools, most of which are already installed on the HPC.  \n",
    "\n",
    "It's important to keep in mind that each of these steps can be done with a different tool.  It's the collection of all\n",
    "these tools and the order they're applied that makes an analysis *pipeline*.  Be sure to document all your steps when \n",
    "working on your own projects.\n",
    "\n",
    "# Processing from scratch\n",
    "\n",
    "## Quality control\n",
    "\n",
    "When you get your raw reads from the sequencer(.fastq files), there is usually some sort of QC report that comes with them that can\n",
    "tell of potential problems with the sequencing such as low read counts, a drop in quality after a certain read length,\n",
    "or problems in specific spots of the flowcell.\n",
    "\n",
    "If you don't have a QC report, it's easy enough to generate one yourself with \n",
    "[*fastqc*](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/).\n",
    "\n",
    "Once it's installed, it can be run at the command line like:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17b24b54",
   "metadata": {
    "eval": false
   },
   "source": [
    "%%bash\n",
    "fastqc samp1.fq samp2.fq samp3.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792d221",
   "metadata": {},
   "source": [
    "## Trimming adapters\n",
    "\n",
    "The adapters usually need to be taken off from the fastq reads before they can be aligned to a reference genome.\n",
    "I like to use a tool called [*trim_galore*](https://github.com/FelixKrueger/TrimGalore) which works for both \n",
    "single and paired reads.\n",
    "\n",
    "If you know the adapter sequence, you can plug this into the trimming tool to chop it of from the reads, or if\n",
    "you know that a standard adapter was used, they can be removed with default parameters.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1bba52c",
   "metadata": {
    "eval": false,
    "lines_to_next_cell": 2
   },
   "source": [
    "%%bash\n",
    "trim_galore --paired samp1_r1.fq samp1_r2.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3b6a7",
   "metadata": {},
   "source": [
    "## Alignment\n",
    "\n",
    "This is the most time intensive part of the pipeline, and involves mapping the *small* fastq reads to\n",
    "the *long* chromosomes of a known reference genome.  The reference needs to be indexed to allow for faster comparisons,\n",
    "and special care needs to be taken to account for splicings across exons when dealing with RNA.\n",
    "\n",
    "A popular aligner is [*star*](https://github.com/alexdobin/STAR), which is extremely fast and handles splicing, but\n",
    "has a very large memory requirement(>20GB), so unless you have a very powerful machine, it needs to be run on the HPC.\n",
    "\n",
    "Another option with a much lower memory footprint is [*tophat2*](https://ccb.jhu.edu/software/tophat/index.shtml).  This\n",
    "one is an older program, but still handles splicing and can be run on a low end laptop.\n",
    "\n",
    "Whichever tool you choose for the alignment, you'll have to get acquainted with its operating procedures and parameter settings. \n",
    "I find it easier to start with a working example than reading through a manual, and luckily, most aligners have\n",
    "pretty good documentation with vignettes and small sample datasets to work through that to help you familiarize yourself\n",
    "with the software.\n",
    "\n",
    "## Feature counting\n",
    "\n",
    "This step is all about quantifying gene expression.  Genes regions must be specified in some format, usually as a .gtf\n",
    "or .gff file, which contains the chromosome, start, stop of each intron/exon and how they are related to each other.\n",
    "A program is then used to enumerate the aligned reads over each transcript accounting for various ways genes can overlap.\n",
    "A popular tool that is laptop friendly is [HTSeq](https://htseq.readthedocs.io/en/latest/htseqcount.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d0d0b",
   "metadata": {},
   "source": [
    "## Running the pipeline\n",
    "\n",
    "Here's an example that shows how to process fastq files from start to finish on the Einstein HPC.\n",
    "The `star` aligner has a special feature that allows for soft clipping at the start or end of a read,\n",
    "which lets us skip the step of trimming adapters.  There's also a way to count the genes during \n",
    "alignment by running it with the `--quantMode GeneCounts` parameter -- another step handled \n",
    "without having to run a separate program."
   ]
  },
  {
   "cell_type": "raw",
   "id": "036a7f6a",
   "metadata": {
    "language": "css",
    "tags": [
     "remove_input"
    ]
   },
   "source": [
    "pre, code {white-space:pre !important; overflow-x:auto}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f710055",
   "metadata": {},
   "source": [
    "### run1_star.sh\n",
    "\n",
    "The pipeline script below has a simple calling form, and can be submitted to the HPC's \n",
    "[*slurm workload manager*](https://slurm.schedmd.com/overview.html) \n",
    "with the `sbatch` command.\n",
    "\n",
    "`sbatch slurm_start_hg38.sh sampName sampR1.fastq.gz sampR2.fastq.gz`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbea493d",
   "metadata": {
    "eval": false,
    "file": "scripts/run1_star.sh"
   },
   "source": [
    "%%bash\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --partition normal\n",
    "#SBATCH --job-name=starRNA\n",
    "#SBATCH --output=starRNA_%j\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH -n 24\n",
    "#SBATCH --time=48:0:0\n",
    "\n",
    "#maybe run ~/.bashrc?\n",
    "\n",
    "source ~/.bashrc\n",
    "\n",
    "conda activate bio-python2\n",
    "module load STAR/2.7.11a \n",
    "module load samtools/1.9\n",
    "\n",
    "REF=/gs/gsfs0/users/kpradha1/projects/star_hg38\n",
    "\n",
    "\n",
    "SNAME=$1\n",
    "FQ1=$2\n",
    "FQ2=$3\n",
    "\n",
    "\n",
    "ulimit -n 10000\n",
    "\n",
    "\n",
    "STAR --genomeDir $REF \\\n",
    "--runThreadN 24 \\\n",
    "--readFilesIn $FQ1 $FQ2 \\\n",
    "--outFileNamePrefix $SNAME/ \\\n",
    "--readFilesCommand zcat \\\n",
    "--outSAMtype BAM SortedByCoordinate \\\n",
    "--outSAMunmapped Within \\\n",
    "--outSAMattributes Standard \\\n",
    "--outFilterType                  BySJout \\\n",
    "--outFilterMultimapNmax          20      \\\n",
    "--alignSJoverhangMin             8       \\\n",
    "--alignSJDBoverhangMin           1       \\\n",
    "--outFilterMismatchNmax          999     \\\n",
    "--outFilterMismatchNoverLmax     0.06    \\\n",
    "--alignIntronMin                 20      \\\n",
    "--alignIntronMax                 1000000 \\\n",
    "--alignMatesGapMax               1000000 \\\n",
    "--twopassMode None \\\n",
    "--quantMode GeneCounts\n",
    "\n",
    "#rename file and index it\n",
    "cp $SNAME/Aligned.sortedByCoord.out.bam $SNAME/${SNAME}_sorted.bam\n",
    "samtools index $SNAME/${SNAME}_sorted.bam $SNAME/${SNAME}_sorted.bai\n",
    "\n",
    "#gene counts\n",
    "cp $SNAME/ReadsPerGene.out.tab $SNAME/${SNAME}_ReadsPerGene.out.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57db80",
   "metadata": {},
   "source": [
    "### bash loop\n",
    "\n",
    "If you have more than a few files to process, you won't want to type all that\n",
    "out at the command line.  Even copy/pasting to a separate file and editing \n",
    "by hand is prone to error and should be avoided if possible.\n",
    "A better way is to write a shell script to prepare the calls for you.\n",
    "There are many ways to do this, but [bash](https://linuxconfig.org/bash-scripting-tutorial) \n",
    "probably the most popular and is available on most computers as the default shell.\n",
    "\n",
    "In the code below, I'm looping over all fastq files of the first paired ends in a directory,\n",
    "and working with them through a series of [piped](https://en.wikipedia.org/wiki/Pipeline_(Unix)) programs \n",
    "\n",
    "The first `sed` substitution finds the name of the 2nd paired end from the original filename.\n",
    "\n",
    "The second `sed` substitution finds the name of the sample from the original filename, and adds\n",
    "a 'star' prefix to the string.\n",
    "\n",
    "The `echo` command, prints out what we want to run.\n",
    "\n",
    "The final `>|` [redirect](https://en.wikipedia.org/wiki/Redirection_(computing)) command saves it all in a file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75a08c",
   "metadata": {},
   "source": [
    "The loop doesn't execute anything, it just writes out the commands we want to run\n",
    "into a separate file.  To execute that file, you run it at the command line.\n",
    "\n",
    "The bash loop below is essentially a script that writes another script.  I like to\n",
    "do it this way so I can look over the code and catch spelling errors and mistakes\n",
    "before attempting to run it on the HPC."
   ]
  },
  {
   "cell_type": "raw",
   "id": "377a415d",
   "metadata": {
    "eval": false
   },
   "source": [
    "%%bash\n",
    "\n",
    "for fq1 in fq/*R1_001*.fastq.gz\n",
    "do\n",
    "    #echo $fq1\n",
    "    fq2=`echo $fq1 | sed 's/R1/R2/'`     #echo $fq2\n",
    "    nam=`echo $fq1 | sed 's/_.*//' | sed 's/fq\\///'`\n",
    "    nam=\"star$nam\"\n",
    "    #nam=\"samp$nam\"\n",
    "    #echo $nam\n",
    "    #echo \"sbatch slurm_rnaPipeline.sh $nam $fq1 $fq2\"\n",
    "    echo \"sbatch slurm_star_hg38.sh $nam $fq1 $fq2\"\n",
    "done >| run1_star.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065be98",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### slurm_star_hg38.sh"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a475ce19",
   "metadata": {
    "eval": false,
    "file": "scripts/slurm_star_hg38.sh"
   },
   "source": [
    "%%bash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222719d4",
   "metadata": {},
   "source": [
    "## Assembling the count matrix\n",
    "\n",
    "What we have now is a set of count files that have the number of reads mapping to each gene, one per sample.\n",
    "These can be loaded and merged in R quite easily, to be made ready for the downstream analysis described in\n",
    "the later section of this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2434e3",
   "metadata": {
    "eval": true,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#get the count files\n",
    "pfiles = list.files(path = paste0(filepath,\"/counts_rna\"),\n",
    "    pat = \".*star.*.tab\", full = TRUE, recursive = TRUE)\n",
    "\n",
    "#load the count files and just use the first 2 columns\n",
    "pcounts = lapply(pfiles, function(f){\n",
    "    print(f)\n",
    "    try({\n",
    "        x = read.csv(f, sep=\"\\t\", header=F)\n",
    "        #remove bad rows\n",
    "        x = x[grepl(x[,1], pat=\"ENSG\"),]\n",
    "        y = data.frame(ensg=x[,1], counts=x[,2])\n",
    "        y\n",
    "    }, silent=T)\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ddf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove NAs\n",
    "names(pcounts) = pfiles\n",
    "ix = unlist(lapply(pcounts, function(a){class(a) != \"try-error\"}))\n",
    "pcounts = pcounts[ix]\n",
    "is.na(pcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge into a data.frame\n",
    "x = do.call(cbind, lapply(pcounts, function(a){\n",
    "\ta$counts\n",
    "}))\n",
    "#make the names easier to read\n",
    "colnames(x) = gsub(names(pcounts), pat=\".*/(.*)_ReadsPerGene.out.tab\", rep=\"\\\\1\")\n",
    "rownames(x) = pcounts[[1]][,1]\n",
    "\n",
    "\n",
    "#get rid of NA counts\n",
    "ix2 = which(apply(x, 1, function(a){\n",
    "    !any(is.na(a))\n",
    "}))\n",
    "x=x[ix2,]\n",
    "\n",
    "#take out the rownames that have __ in them\n",
    "#only use the ENSG rows\n",
    "x = x[grepl(rownames(x), pat=\"ENSG\"),]\n",
    "\n",
    "#take out the dot?\n",
    "rownames(x) = gsub(rownames(x), pat=\"\\\\..*\", rep=\"\")\n",
    "\n",
    "head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6d09f",
   "metadata": {},
   "source": [
    "# Loading from GEO\n",
    "\n",
    "> [Gene Expression Omnibus(GEO)](https://www.ncbi.nlm.nih.gov/geo/) is a public functional \n",
    "> genomics data repository supporting MIAME-compliant data submissions. \n",
    "> Array- and sequence-based data are accepted. Tools are provided to help users query \n",
    "> and download experiments and curated gene expression profiles.   \n",
    "\n",
    "Though it started as a repository for microarray data, it has grown through the years, and now accepts\n",
    "next-gen sequencing datasets of all kinds, including RNA, ATAC, OxBS, singlecell, etc.\n",
    "It's relatively easy to upload your own data, and there are many ways to download from \n",
    "the repository, including programmatic interfaces in R and other languages.\n",
    "\n",
    "In the example below, we'll be downloading a dataset with the accession ID of GSE132040.\n",
    "Every project in GEO is given a unique identifier, as well as every sample, platform, and dataset in the series.\n",
    "Searching for a specific dataset can be done through the [website](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi), \n",
    "but usually, you'll get the accession ID from the paper you're reading.  Since GEO is so popular\n",
    "a [Ctrl-F] search of \"GSE\" in the pdf usually brings you right to the accession number without having to search\n",
    "through all the supplementaries.\n",
    "\n",
    "We'll be using the `GEOquery` Bioconductor package to interface to the GEO repository.  \n",
    "While this package has very robust methods for working with microarray expression data,\n",
    "it doesn't have every feature available for all next-gen seq types.  For RNAseq data,\n",
    "most times you'll have to download the processed gene count matrix manually, then link it with \n",
    "the phenotypic data that's stored on GEO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fcd1d",
   "metadata": {
    "cache": true,
    "name": "GEO phenodata download"
   },
   "outputs": [],
   "source": [
    "# #create a folder/directory for where geo downloads will be cached\n",
    "# if (!dir.exists(\"geo\")){\n",
    "#     dir.create(\"geo\")\n",
    "# }\n",
    "\n",
    "# #download geo data with id GSE132040 and save to \"geo\" dir\n",
    "# dat <- getGEO(\"GSE132040\", destdir = \"geo\")\n",
    "# head(dat)\n",
    "\n",
    "\n",
    "\n",
    "# use local GEO files \n",
    "dat <- vector(\"list\",length = 1)\n",
    "names(dat) <- \"GSE132040_series_matrix.txt.gz\"   \n",
    "dat[[1]] <-getGEO(filename= paste0(filepath,\"/geo/GSE132040_series_matrix.txt.gz\"))\n",
    "head(dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543b0d4",
   "metadata": {},
   "source": [
    "## Loading the phenotype data\n",
    "\n",
    "GEOquery offers a consistent way for accessing phenotype info from the datasets in GEO,\n",
    "using the `pData` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa8464",
   "metadata": {
    "name": "loading the phenotype data"
   },
   "outputs": [],
   "source": [
    "#load the phenotype data from GEO, obtain phenodata\n",
    "#some GSE's have more than 1 of dataset, getGEO returns them in a list\n",
    "phenodata <- pData(dat[[1]])\n",
    "head(phenodata)\n",
    "#Alternatively, you can do the following \n",
    "#phenodata <- dat[[\"GSE132040_series_matrix.txt.gz\"]]@phenoData@data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bf8aa",
   "metadata": {},
   "source": [
    "## Loading the expression data\n",
    "\n",
    "Accessing expression data is usually handled with the `exprs` function, but not in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c3d7d",
   "metadata": {
    "name": "load the expression data"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Load the expression data\n",
    "rnadata.geo <- exprs(dat[[1]])\n",
    "dim(rnadata.geo) #0 rows?!\n",
    "\n",
    "#the columns of rnadata should match up to the rows of phenodata)\n",
    "#cbind(colnames(rnadata),rownames(phenodata))\n",
    "all(colnames(rnadata.geo) == rownames(phenodata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d941b77",
   "metadata": {},
   "source": [
    "Notice the ExpressionSet assayData has 0 features, and 947 samples.  This is the matrix that\n",
    "holds the expression counts for each gene, and it's empty!\n",
    "\n",
    "The expression data is not accessible from the usual exprs function,\n",
    "probably because this is bulk RNAseq data and not microarray,\n",
    "but we can still download the processed data from the GEO as a supplementary table. \n",
    "\n",
    "[GEO:  GSE132040](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE132040)\n",
    "\n",
    "[GSE132040_190214_A00111_0269_AHH3J3DSXX_190214_A00111_0270_BHHMFWDSXX.csv.gz](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE132040&format=file&file=GSE132040%5F190214%5FA00111%5F0269%5FAHH3J3DSXX%5F190214%5FA00111%5F0270%5FBHHMFWDSXX%2Ecsv%2Egz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666d46b",
   "metadata": {
    "cache": true,
    "name": "load the exp data"
   },
   "outputs": [],
   "source": [
    "\n",
    "#you'll need to unzip the file first\n",
    "#rnadata <- read.csv(\"GSE132040_190214_A00111_0269_AHH3J3DSXX_190214_A00111_0270_BHHMFWDSXX.csv\")\n",
    "\n",
    "#here's a trick to load large files using the data.table function.  It's much faster than read.csv and even works on zipped files\n",
    "rnadata <- data.frame(fread(paste0(filepath,\"/GSE132040_190214_A00111_0269_AHH3J3DSXX_190214_A00111_0270_BHHMFWDSXX.csv.gz\")))\n",
    "dim(rnadata)\n",
    "\n",
    "#look at the first 5 rows and first 10 columns to get an idea of the data\n",
    "#View(rnadata[1:5, 1:10])\n",
    "#print(rnadata[1:5, 1:10])\n",
    "\n",
    "rnadata[1:5, 1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4aa851",
   "metadata": {},
   "source": [
    "Take a look at column 1 in the data.frame above.\n",
    "\n",
    "The first column is the Gene id, the rest are the rna counts from each sample.\n",
    "\n",
    "You'll see why later one, but for now, it would be easier to work with if we \n",
    "use the first column as the rownames of the data.frame and only use\n",
    "the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1fbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table(duplicated(rnadata$gene)) # check if any duplication gene names \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add73149",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "genename to rowname"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rownames(rnadata) <- rnadata$gene  # Assign the first column to the rownames\n",
    "rnadata$gene <- NULL #remove the column from the rest of the matrix\n",
    "\n",
    "class(rnadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnadata[1:5, 1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e0289",
   "metadata": {},
   "source": [
    "## Matching phenotype data to expression data\n",
    "\n",
    "In order to link the two data sources, we need to find an identifier that is common to both.\n",
    "\n",
    "Notice the columns of `rnadata` all have a naming structure that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc861368",
   "metadata": {
    "name": "view data structure - 1"
   },
   "outputs": [],
   "source": [
    "cbind(head(colnames(rnadata)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0cdb7",
   "metadata": {},
   "source": [
    "If you look through the columns of `phenodata` that we got from GEO, the only thing that comes close is the *title*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd50a4d0",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "view data structure - 2"
   },
   "outputs": [],
   "source": [
    "cbind(head(phenodata$title))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45dd45",
   "metadata": {},
   "source": [
    "The phenodata titles do not match the csv file exactly, so we need to do some string manipulation \n",
    "to transform the column names of the csv to match a section of the title in phenodata.\n",
    "\n",
    "If we chop off the very last part \".genecode.vM19\" of the colnames in the csv file\n",
    "they will match what's inside the brackets of phenodata$title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe6034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use gsub to manipulate the string. in this case, replace a part of a string.\n",
    "colnames(rnadata) <- gsub(colnames(rnadata), pattern=\".gencode.vM19\", replace=\"\")\n",
    "                     \n",
    "cbind(head(colnames(rnadata))) # after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027edf87",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "modify sample names and match"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a new column in phenodata called \"tmp_id\" \n",
    "# that has the sample identifier extracted from the title\n",
    "# we can use replace again noticed I used \\\\ in front of ( ) and [ ], because they are special characters \n",
    "# a more general approach is to use regular expression \n",
    "phenodata$tmp_id <- gsub(phenodata$title, pattern=\"Tabula Muris Senis \\\\(bulk RNA-seq\\\\) \\\\[\", replace=\"\")\n",
    "phenodata$tmp_id <- gsub(phenodata$tmp_id, pattern=\"\\\\]\", replace=\"\")\n",
    "\n",
    "cbind(head(phenodata$tmp_id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets also get rid of :chr1 in some colnames\n",
    "colnames(phenodata) <- gsub(colnames(phenodata), pattern=\":ch1\", replace=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65541b",
   "metadata": {},
   "source": [
    "We have to make sure that the sample order of the csv sample matches the sample order of the phenotype data.\n",
    "\n",
    "As of now, this is not the case...you have to reorder the samples in the two matrices so they correspond to each other.\n",
    "\n",
    "It's very easy to mess up here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5671c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is every sample accounted for? yes\n",
    "all(phenodata$tmp_id %in% colnames(rnadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fadb114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#but they don't match\n",
    "head(cbind(phenodata$tmp_id, colnames(rnadata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#better to work with a temporary variable so you can check your work\n",
    "\n",
    "#reorder the rows of phenodata to match the columns of rnadata\n",
    "phenodata_reordered <- phenodata[match(colnames(rnadata), phenodata$tmp_id),]\n",
    "\n",
    "#check it again (now they match)\n",
    "head(cbind(phenodata_reordered$tmp_id, colnames(rnadata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac6fbc",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "reorder phenodata"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#from now on we will replace phenodata with phenodata_reordered\n",
    "phenodata <- phenodata_reordered\n",
    "rm(phenodata_reordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92ab4a",
   "metadata": {},
   "source": [
    "## Selecting a smaller subset\n",
    "\n",
    "The full dataset from GSE132040, has `r ncol(rnadata)` samples.  DESeq2 is capable of handling datasets this large, \n",
    "but it could take hours to run on a dataset like this.  \n",
    "\n",
    "For our example, we'll be using a smaller subset of just the bone and brain tissues from 1 month postnatal samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run deseq on a subset of rnadata for demonstration purposes\n",
    "table(phenodata$tissue, phenodata$age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c731ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets just look at bone vs brain\n",
    "#in 1 months postnatal mice\n",
    "\n",
    "#extract the relevant rows from phenotype data\n",
    "phenodata_small <- phenodata[phenodata$tissue %in% c(\"Bone\", \"Brain\"),]\n",
    "phenodata_small <- phenodata_small[phenodata_small$age %in% c(\"1 months postnatal\"),]\n",
    "\n",
    "\n",
    "#extract the relevant columns from count data\n",
    "rnadata_small <- rnadata[,colnames(rnadata) %in% phenodata_small$tmp_id]\n",
    "\n",
    "dim(phenodata_small)\n",
    "dim(rnadata_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e35904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the IDs match up\n",
    "table(phenodata_small$tmp_id == colnames(rnadata_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c00a1c",
   "metadata": {
    "name": "subset samples for Deseq"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#use the new ids instead of the GSM ids\n",
    "#deseq requires the rownames from the info match the colnames of the counts\n",
    "rownames(phenodata_small) <- phenodata_small$tmp_id\n",
    "\n",
    "\n",
    "#make sure the column names don't have any special characters like \":\"\n",
    "colnames(phenodata_small) <- make.names(colnames(phenodata_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a862d",
   "metadata": {},
   "source": [
    "# Deseq2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae54a4e",
   "metadata": {},
   "source": [
    "There's a great [tutorial](https://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html) \n",
    "by Michael Love, the developer of DESeq2, that is hands down the best resource out there\n",
    "for learning how to do differential expression analysis in R.  It's a long read,\n",
    "but it's full of details and explanations of every procedure in the package along with all the\n",
    "code needed to run them.  If you're using DESeq2 for your own analyses, you should read it over at least once.\n",
    "\n",
    "To summarize the tutorial, DE is carried out by running a regression of the gene counts on\n",
    "one or more variables, e.g. gender, age, treatment condition.  If you think of the usual linear regression as `Y ~ X`\n",
    "on a 2D scatter plot, the independent variable on the *Y* axis is the gene count and the dependent variable \n",
    "on the *X* axis is the variable and each scatter plot dot is a sample.  \n",
    "\n",
    "General linear modelling assumes the residuals are normally distributed, \n",
    "but with our integer gene counts, it's not the best method to use.  Poisson regression works well with\n",
    "integer counts, but built into the model's distribution is the assumption that the mean is the same as the variance.\n",
    "Negative binomial regression is like Poisson, but the relationship between the mean and variance is\n",
    "governed by a dispersion parameter, so it can be higher or lower than the mean.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940504d9",
   "metadata": {},
   "source": [
    "DESeq2 uses negative binomial regression to look for association\n",
    "between the X and Y variables and uses info from all genes to estimate a proper dispersion parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3349ab",
   "metadata": {},
   "source": [
    "The main DESeq2 function requires 3 inputs:\n",
    "\n",
    "* `colDat`:  a data.frame with `nSamples` rows, and `nVariables` columns.  \n",
    "This holds the phenotypic information of every sample in your study.\n",
    "\n",
    "* `countData`:  a matrix with `nGenes` rows and `nSamples` columns.  These are your \n",
    "raw gene counts.  Note the order of the rows/columns is transposed from the usual R standard of\n",
    "having one observation per row.\n",
    "\n",
    "* `design`:  a formula describing the regression of the gene counts on specific columns of `colDat`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc785b",
   "metadata": {},
   "source": [
    "The first two parameters are straightforward, the last can be tricky if you're not used to R's syntax. \n",
    "\n",
    "A `formula` has a left hand side and a right hand side separated by a `~`.  \n",
    "The LHS is the dependent variable, and in our case, the gene counts.\n",
    "The RHS are the variables you want to regress upon.  You can use more than one by separating them \n",
    "by `+`.  If you want to include interaction terms between two variables you use a `:`. \n",
    "As shorthand, if you want to include both main effects and interaction terms between variables you use a `*`.\n",
    "\n",
    "It's easier to understand with examples:\n",
    "\n",
    "* `Y ~ X1 + X2` :  A model with Y as the dependent var and X1 & X2 as independent vars:\n",
    "* `Y ~ X1 * X2` :  A model with Y as the dependent var and X1 and X2 as independent vars that includes interaction between X1 and X2:\n",
    "* `Y ~ X1 + X2 + X1:X2` :  Same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527bd13",
   "metadata": {},
   "source": [
    "Most times, samples in an experiment are split by a condition like ctrl vs drug.  In this case you will want to regress on\n",
    "a *grouping* variable that's either dummy coded to 0 or 1, or a categorical factor with each level of your condition. \n",
    "\n",
    "If the RHS of a formula has more than 1 term, the default behavior of DESeq2 only reports stats on the very last one. \n",
    "This makes it very straightforward to control for confounding effects in your model.\n",
    "\n",
    "When using DESeq2, we only need to specify the RHS of the formula.\n",
    "\n",
    "## Running the DE\n",
    "\n",
    "It doesn't matter where your data comes from, whether it was processed by hand or downloaded from a repository, DESeq2\n",
    "treats it all the same.  For a basic analysis, you just need to supply those 3 inputs, run 3 functions, and the package will take care\n",
    "of the rest.\n",
    "\n",
    "For a more involved analysis that prefilters genes and considers alternative shrinkage estimators,\n",
    "you should refer to the DESeq2 manual/tutorial for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b90508",
   "metadata": {
    "cache": true,
    "lines_to_next_cell": 0,
    "message": false,
    "name": "Deseq"
   },
   "outputs": [],
   "source": [
    "\n",
    "#it's always a good idea to explicitly set a categorical variable as a factor\n",
    "#so you can control which is the baseline reference.  Otherwise, it sorts \n",
    "#alphabetically and chooses the first as the ref.\n",
    "phenodata_small$tissue <- factor(phenodata_small$tissue, levels = c(\"Bone\", \"Brain\"))\n",
    "\n",
    "dds <- DESeqDataSetFromMatrix(countData=rnadata_small, colDat=phenodata_small, design = ~tissue)\n",
    "dds <- DESeq(dds) #takes a minute\n",
    "res <- results(dds)\n",
    "res <- as.data.frame(res) #easier to work with data.frames\n",
    "\n",
    "#take a look at the results in excel\n",
    "write.table(res, file=\"res.csv\",sep = \",\",quote = F,row.names = T, col.names = NA)\n",
    "\n",
    "summary(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(res, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa0e49",
   "metadata": {},
   "source": [
    "The result `res` is a data.frame with 6 columns.\n",
    "\n",
    "* baseMean:  The average expression for this gene\n",
    "* log2FoldChange:  The difference in log2 expression between groups\n",
    "* lfcSE:  A measure of the standard error of the log2 fold change\n",
    "* stat:  The statistic used to determine significance\n",
    "* pvalue:  raw p-value\n",
    "* padj:  The adjusted p-value, corrected for multiple comparisons with FDR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c02f60",
   "metadata": {},
   "source": [
    "That's it for the basics of running DESeq2!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d49d6",
   "metadata": {},
   "source": [
    "## Selecting significant up/down regulated genes\n",
    "\n",
    "Once you've written out your results, further downstream analysis can be done in R, \n",
    "or any other environment you're comfortable with.  Excel is often used\n",
    "to filter for interesting genes, which are then copy/pasted directly into\n",
    "an online pathway analysis website such as [Reactome](https://reactome.org/PathwayBrowser/#TOOL=AT).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove results with no counts\n",
    "res <- res[res$baseMean > 0,]\n",
    "#sort by fold change and \n",
    "res <- res[order(res$log2FoldChange),] # turn decreasing = TRUE if want from the largest to the smallest \n",
    "#write the output to a spreadsheet\n",
    "\n",
    "write.table(res,file=\"de_boneVsbrain_age1month.csv\",sep = \",\",quote = F,row.names = T,col.names = NA)\n",
    "\n",
    "dim(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many genes show significant DE after adjusting for multiple comparisons?\n",
    "sum(res$padj < .01, na.rm=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7633322a",
   "metadata": {
    "name": "Deseq - set cutoff"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#what are the genes that have  a log2FC > 2 and an adjusted pvalue < 0.01?\n",
    "res_up <- res[!is.na(res$log2FoldChange),]\n",
    "res_up <- res_up[res_up$log2FoldChange > 2,]\n",
    "res_up <- res_up[!is.na(res_up$padj),]\n",
    "res_up <- res_up[res_up$padj < 0.01,]\n",
    "res_up <- res_up[order(res_up$log2FoldChange,decreasing = TRUE),]\n",
    "\n",
    "res_down <- res[!is.na(res$log2FoldChange),]\n",
    "res_down <- res_down[res_down$log2FoldChange < -2,]\n",
    "res_down <- res_down[!is.na(res_down$padj),]\n",
    "res_down <- res_down[res_down$padj < 0.01,]\n",
    "\n",
    "\n",
    "nrow(res_up)\n",
    "nrow(res_down)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the top 20 in each\n",
    "head(rownames(res_up), 20)\n",
    "head(rownames(res_down), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42335326",
   "metadata": {},
   "source": [
    "## PCA plot\n",
    "\n",
    "It's a good idea to visualize the global expression over the first\n",
    "few principal components to check if there are any outliers or other\n",
    "interesting patterns in your data.  A PCA plot can be used\n",
    "to determine if there is batch effect that needs to be accounted for,\n",
    "or some other condition that needs to be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when the expression data is alinged to the phenotype data\n",
    "# it's easy to run all the usual informatics procedures \n",
    "dim(rnadata_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414e164",
   "metadata": {
    "cache": true,
    "name": "PCA via ggfortify"
   },
   "outputs": [],
   "source": [
    "\n",
    "# the prcomp function complains when there are columns with 0 variance\n",
    "# to fix it, remove the genes that have no variance\n",
    "gene_var <- apply(rnadata_small, 1, var) > 0 \n",
    "table(gene_var)\n",
    "\n",
    "rnadata_filtered <- rnadata_small[gene_var,]\n",
    "dim(rnadata_filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 <- prcomp(t(rnadata_filtered), scale=T)\n",
    "\n",
    "#plot the first 2 principal components, colored by tissue type\n",
    "#pdf(\"test1.pdf\")\n",
    "autoplot(pca1, data=phenodata_small, colour='tissue', shape=\"Sex\")\n",
    "#dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223019d1",
   "metadata": {},
   "source": [
    "## Volcano plot\n",
    "Overall results from a DE analysis are usually shown in a *volcano plot* that \n",
    "has the log2FC in the x-axis, and a `-log*()` transformation of the p-value in the y-axis.\n",
    "Genes that have both high log2FC and low p-values should be examined further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d054dd5",
   "metadata": {},
   "source": [
    "It's not difficult to make the plots yourself in base R or ggplot, but a better\n",
    "option may be to to use the \n",
    "[EnhancedVolcano](https://bioconductor.org/packages/release/bioc/vignettes/EnhancedVolcano/inst/doc/EnhancedVolcano.html)\n",
    "package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7af06f",
   "metadata": {
    "cache": true,
    "fig.height": 10,
    "fig.width": 10,
    "lines_to_next_cell": 0,
    "name": "Volcano plot via enhancedVolcano - 1"
   },
   "outputs": [],
   "source": [
    "\n",
    "vlnPlot1 <- EnhancedVolcano(res,\n",
    "    lab = rownames(res),\n",
    "    #subtitle = NULL, #get rid of the subtitle\n",
    "    #colCustom = keyvals.colour, #give customized color\n",
    "    x = 'log2FoldChange',\n",
    "    y = 'padj',\n",
    "    #xlim = c(-30,30), #x axis range\n",
    "    #ylim = c(0,300), # y axis range\n",
    "    title = 'DE_Bone_vs_Brain: 1month', # title label\n",
    "    xlab= bquote(~Log[2]~ 'fold change'), # x axis label\n",
    "    ylab= bquote(~-Log[10]~ 'Padj'), # y axis label\n",
    "    caption = NULL,\n",
    "    pCutoff = 0.05,\n",
    "    FCcutoff = 2,\n",
    "    pointSize = 2.0)\n",
    "\n",
    "#pdf(\"test2.pdf\")\n",
    "vlnPlot1\n",
    "#dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68864bd8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "fig.height,file,cache,tags,name,message,fig.width,eval,language,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R [conda env:spatial_singulomics]",
   "language": "R",
   "name": "conda-env-spatial_singulomics-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
